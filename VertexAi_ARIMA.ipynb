{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7bf9d7-a0d4-4de5-8f73-9ae3c9f5ebd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7abaff69cec40459a20913b7e8e9a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e11782b71594128a3979dd0b4c3c50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery df\n",
    "SELECT *\n",
    "FROM `stockswhatsup.stocks_data_historical.stocks_data_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb3a8c1-f69a-4a4f-b883-44f5956abc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmdarima\n",
      "  Using cached pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.3.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.25.2)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (0.14.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.26.18)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (68.2.2)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.19->pmdarima) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.19->pmdarima) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->pmdarima) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Using cached pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "Installing collected packages: pmdarima\n",
      "Successfully installed pmdarima-2.0.4\n",
      "Collecting sktime\n",
      "  Using cached sktime-0.25.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in /opt/conda/lib/python3.10/site-packages (from sktime) (1.25.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from sktime) (23.2)\n",
      "Requirement already satisfied: pandas<2.2.0,>=1.1 in /opt/conda/lib/python3.10/site-packages (from sktime) (2.0.3)\n",
      "Collecting scikit-base<0.7.0 (from sktime)\n",
      "  Using cached scikit_base-0.6.2-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: scikit-learn<1.4.0,>=0.24 in /opt/conda/lib/python3.10/site-packages (from sktime) (1.3.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2 in /opt/conda/lib/python3.10/site-packages (from sktime) (1.11.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0,>=1.1->sktime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0,>=1.1->sktime) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0,>=1.1->sktime) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.0,>=0.24->sktime) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.0,>=0.24->sktime) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2.0,>=1.1->sktime) (1.16.0)\n",
      "Using cached sktime-0.25.0-py3-none-any.whl (21.7 MB)\n",
      "Using cached scikit_base-0.6.2-py3-none-any.whl (122 kB)\n",
      "Installing collected packages: scikit-base, sktime\n",
      "Successfully installed scikit-base-0.6.2 sktime-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pmdarima\n",
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfcf7f2-0d62-4943-af17-57cf53ef9db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d7162-5e9a-4101-a27c-fb6758e9a0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize bic\n",
      " ARIMA(1,1,1)(0,0,0)[7] intercept   : BIC=3887.552, Time=0.40 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7] intercept   : BIC=3920.072, Time=0.11 sec\n",
      " ARIMA(1,1,0)(1,0,0)[7] intercept   : BIC=3889.040, Time=0.99 sec\n",
      " ARIMA(0,1,1)(0,0,1)[7] intercept   : BIC=3887.527, Time=1.13 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7]             : BIC=3926.363, Time=0.12 sec\n",
      " ARIMA(0,1,1)(0,0,0)[7] intercept   : BIC=3881.006, Time=0.18 sec\n",
      " ARIMA(0,1,1)(1,0,0)[7] intercept   : BIC=3887.528, Time=1.01 sec\n",
      " ARIMA(0,1,1)(1,0,1)[7] intercept   : BIC=3894.141, Time=2.47 sec\n",
      " ARIMA(0,1,2)(0,0,0)[7] intercept   : BIC=3887.565, Time=0.70 sec\n",
      " ARIMA(1,1,0)(0,0,0)[7] intercept   : BIC=3882.505, Time=0.25 sec\n",
      " ARIMA(1,1,2)(0,0,0)[7] intercept   : BIC=3894.067, Time=0.56 sec\n",
      " ARIMA(0,1,1)(0,0,0)[7]             : BIC=3883.153, Time=0.09 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,1)(0,0,0)[7] intercept\n",
      "Total fit time: 8.065 seconds\n",
      "Performing stepwise search to minimize bic\n",
      " ARIMA(1,1,1)(0,0,0)[7] intercept   : BIC=3049.876, Time=0.38 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7] intercept   : BIC=3063.184, Time=0.10 sec\n",
      " ARIMA(1,1,0)(1,0,0)[7] intercept   : BIC=3049.776, Time=0.99 sec\n",
      " ARIMA(0,1,1)(0,0,1)[7] intercept   : BIC=3050.251, Time=1.11 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7]             : BIC=3056.599, Time=0.12 sec\n",
      " ARIMA(1,1,0)(0,0,0)[7] intercept   : BIC=3043.283, Time=0.17 sec\n",
      " ARIMA(1,1,0)(0,0,1)[7] intercept   : BIC=3049.761, Time=0.91 sec\n",
      " ARIMA(1,1,0)(1,0,1)[7] intercept   : BIC=3055.947, Time=2.62 sec\n",
      " ARIMA(2,1,0)(0,0,0)[7] intercept   : BIC=3049.880, Time=0.40 sec\n",
      " ARIMA(0,1,1)(0,0,0)[7] intercept   : BIC=3043.749, Time=0.18 sec\n",
      " ARIMA(2,1,1)(0,0,0)[7] intercept   : BIC=3056.434, Time=0.44 sec\n",
      " ARIMA(1,1,0)(0,0,0)[7]             : BIC=3036.689, Time=0.08 sec\n",
      " ARIMA(1,1,0)(1,0,0)[7]             : BIC=3043.181, Time=0.37 sec\n",
      " ARIMA(1,1,0)(0,0,1)[7]             : BIC=3043.166, Time=0.39 sec\n",
      " ARIMA(1,1,0)(1,0,1)[7]             : BIC=3049.352, Time=0.95 sec\n",
      " ARIMA(2,1,0)(0,0,0)[7]             : BIC=3043.286, Time=0.19 sec\n",
      " ARIMA(1,1,1)(0,0,0)[7]             : BIC=3043.282, Time=0.18 sec\n",
      " ARIMA(0,1,1)(0,0,0)[7]             : BIC=3037.156, Time=0.08 sec\n",
      " ARIMA(2,1,1)(0,0,0)[7]             : BIC=3049.707, Time=0.30 sec\n",
      "\n",
      "Best model:  ARIMA(1,1,0)(0,0,0)[7]          \n",
      "Total fit time: 10.037 seconds\n",
      "Performing stepwise search to minimize bic\n",
      " ARIMA(1,1,1)(0,0,0)[7] intercept   : BIC=3249.269, Time=0.55 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7] intercept   : BIC=3257.059, Time=0.16 sec\n",
      " ARIMA(1,1,0)(1,0,0)[7] intercept   : BIC=3249.745, Time=0.98 sec\n",
      " ARIMA(0,1,1)(0,0,1)[7] intercept   : BIC=3251.067, Time=1.14 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7]             : BIC=3250.587, Time=0.15 sec\n",
      " ARIMA(1,1,1)(1,0,0)[7] intercept   : BIC=3255.781, Time=1.40 sec\n",
      " ARIMA(1,1,1)(0,0,1)[7] intercept   : BIC=3255.758, Time=2.03 sec\n",
      " ARIMA(1,1,1)(1,0,1)[7] intercept   : BIC=3252.492, Time=3.55 sec\n",
      " ARIMA(0,1,1)(0,0,0)[7] intercept   : BIC=3244.593, Time=0.53 sec\n",
      " ARIMA(0,1,1)(1,0,0)[7] intercept   : BIC=3251.093, Time=1.16 sec\n",
      " ARIMA(0,1,1)(1,0,1)[7] intercept   : BIC=3247.648, Time=2.69 sec\n",
      " ARIMA(0,1,2)(0,0,0)[7] intercept   : BIC=3249.672, Time=0.70 sec\n",
      " ARIMA(1,1,0)(0,0,0)[7] intercept   : BIC=3243.226, Time=0.26 sec\n",
      " ARIMA(1,1,0)(0,0,1)[7] intercept   : BIC=3249.723, Time=0.94 sec\n",
      " ARIMA(1,1,0)(1,0,1)[7] intercept   : BIC=3246.411, Time=2.19 sec\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(stock_data, stock_symbol):\n",
    "    \"\"\"\n",
    "    Preprocesses stock data by filling missing dates and interpolating missing values.\n",
    "    \n",
    "    Args:\n",
    "        stock_data (DataFrame): Input stock data with 'date' and 'volume_weighted_avg_price' columns.\n",
    "        stock_symbol (str): Stock symbol for labeling.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Preprocessed stock data with a continuous date range and interpolated prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_date = stock_data.date.min()\n",
    "        end_date = stock_data.date.max()\n",
    "        full_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        \n",
    "        full_date_range_df = pd.DataFrame({f'{stock_symbol}_full_date_range': full_date_range}) \n",
    "        full_date_range_df[f'{stock_symbol}_full_date_range'] = pd.to_datetime(full_date_range_df[f'{stock_symbol}_full_date_range'])\n",
    "        full_date_range_df = full_date_range_df.reset_index(drop=True)\n",
    "        \n",
    "        stock_data['date'] = pd.to_datetime(stock_data['date'])\n",
    "        stock_data = stock_data.reset_index(drop=True)\n",
    "        \n",
    "        continuous_df = pd.merge(full_date_range_df, stock_data, how='left', left_on=f'{stock_symbol}_full_date_range', right_on='date')\n",
    "        continuous_df.set_index(f'{stock_symbol}_full_date_range', inplace=True)\n",
    "        continuous_df.index = pd.DatetimeIndex(continuous_df.index).to_period('D')\n",
    "\n",
    "        continuous_df = continuous_df[['volume_weighted_avg_price']].interpolate(method='time')\n",
    "        continuous_df.index = continuous_df.index.to_timestamp()\n",
    "        return continuous_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Failed to preprocess the data: {e}')\n",
    "\n",
    "def auto_arima_forecast(preprocessed_stock_data, stock):\n",
    "    \"\"\"\n",
    "    Applies Auto ARIMA forecasting on preprocessed stock data.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_stock_data (DataFrame): Preprocessed stock data with continuous date range.\n",
    "        stock (str): Stock symbol for labeling.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Forecasted stock prices with confidence intervals.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        last_date = preprocessed_stock_data.index[-1]\n",
    "        forecast_horizon_start = last_date + pd.DateOffset(days=1)\n",
    "        forecast_horizon_end = last_date + pd.DateOffset(days=90)\n",
    "        forecast_horizon_range = pd.date_range(start=forecast_horizon_start, end=forecast_horizon_end, freq='D')\n",
    "\n",
    "        fh = ForecastingHorizon(forecast_horizon_range, is_relative=False)\n",
    "\n",
    "        arima_model = pm.auto_arima(\n",
    "            preprocessed_stock_data,\n",
    "            start_p=1, start_q=1,\n",
    "            max_p=5, max_q=5,\n",
    "            seasonal=True, m=7,\n",
    "            start_P=0, start_Q=0,\n",
    "            max_P = 2, max_Q = 2,\n",
    "            max_D=2,\n",
    "            max_d=2,\n",
    "            alpha=0.05,\n",
    "            test='adf',\n",
    "            seasonal_test='ocsb',\n",
    "            trace=True,\n",
    "            error_action='ignore',\n",
    "            suppress_warnings=True,\n",
    "            stepwise=True,\n",
    "            n_fits=5,\n",
    "            information_criterion='bic',\n",
    "            out_of_sample_size=round(len(preprocessed_stock_data)*0.2)\n",
    "        )\n",
    "\n",
    "        forecast_result, pred_ci = arima_model.predict(\n",
    "            n_periods = 90,\n",
    "            return_conf_int=True,\n",
    "            alpha=0.05)\n",
    "\n",
    "        forecasted_stock_df = pd.DataFrame({'stock_symbol':stock,'forecasted_weighted_avg_price':forecast_result, \n",
    "                                            'ci_lower': pred_ci[:,0], 'ci_upper': pred_ci[:,1]})\n",
    "        forecasted_stock_df.index = fh.to_pandas()\n",
    "        forecasted_stock_df.reset_index(inplace=True)\n",
    "        return forecasted_stock_df\n",
    "    \n",
    "    except Exception as e:\n",
    "            print(f'Failed to forecast with Auto ARIMA: {e}')\n",
    "            \n",
    "def upload_forecast_to_bq(data):\n",
    "    \"\"\"\n",
    "    Uploads forecasted stock data to BigQuery.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Forecasted stock data with 'date', 'stock_symbol', 'forecasted_weighted_avg_price', 'lower_limit', and 'upper_limit' columns.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client()\n",
    "    forecast_table_id = \"stockswhatsup.stocks_data_historical.stocks_forecast\"\n",
    "    \n",
    "    forecast_table_config = bigquery.LoadJobConfig(\n",
    "          schema=[\n",
    "              bigquery.SchemaField(\"date\", bigquery.enums.SqlTypeNames.DATE),\n",
    "              bigquery.SchemaField(\"stock_symbol\", bigquery.enums.SqlTypeNames.STRING),\n",
    "              bigquery.SchemaField(\"forecasted_weighted_avg_price\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "              bigquery.SchemaField(\"lower_limit\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "              bigquery.SchemaField(\"upper_limit\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "          ],\n",
    "          write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "      )\n",
    "\n",
    "    try:\n",
    "        forecast_table_job = client.load_table_from_dataframe(\n",
    "            data, forecast_table_id, job_config=forecast_table_config\n",
    "        )\n",
    "        print('Success: Uploaded Forecasted data to BigQuery')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Failed to upload to BigQuery: {e}')\n",
    "\n",
    "def main(df):\n",
    "    \"\"\"\n",
    "    Main function to execute the entire forecasting process for multiple stocks and upload data to BigQuery table.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame containing stock data with 'stock_symbol', 'date', and 'volume_weighted_avg_price' columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stocks = list(df.stock_symbol.unique())\n",
    "        combined_forecasts = []\n",
    "\n",
    "        for stock in stocks:\n",
    "            stock_df = df[df['stock_symbol']==stock][['volume_weighted_avg_price','date']]\n",
    "            preprocessed_stock_df = preprocess_data(stock_df, stock)\n",
    "            forecasted_stock_df = auto_arima_forecast(preprocessed_stock_df,stock)\n",
    "            combined_forecasts.append(forecasted_stock_df)\n",
    "\n",
    "        combined_forecasts_df = pd.concat(combined_forecasts, ignore_index=True)\n",
    "        combined_forecasts_df.rename(columns={'index':'date', 'ci_lower':'lower_limit', 'ci_upper':'upper_limit'}, inplace=True)        \n",
    "        upload_forecast_to_bq(combined_forecasts_df)\n",
    "        \n",
    "        print('Job finished successfully')\n",
    "    except Exception as e:\n",
    "            print(f'Failed to run the job: {e}')\n",
    "            \n",
    "main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d815632-d3f1-4ae6-a1b1-1e84e1aa9e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
